{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class refinement_module(nn.Module):\n",
    "#     def __init__(self, in_chan1, in_chan2, out_chan, kernel_size=3,stride=1,padding=1):\n",
    "#         super(refinement_module,self).__init__()\n",
    "#         self.convin1 = nn.Sequential(\n",
    "#             nn.Conv2d(in_chan1,int(in_chan1/2), kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "#             nn.ReLU(inplace=True))\n",
    "#         self.convin2 = nn.Sequential(\n",
    "#             nn.Conv2d(in_chan2,int(in_chan2/2), kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "#             nn.ReLU(inplace=True))\n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv2d(int(in_chan1/2)+int(in_chan2/2), out_chan, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "#             nn.ReLU(inplace=True))\n",
    "#         self.subpixelconv = nn.Sequential(\n",
    "#             nn.Conv2d(out_chan, 4*out_chan, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "#             nn.PixelShuffle(2)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self,x1,x2):\n",
    "#         x1_ = self.convin1(x1)\n",
    "#         x2_ = self.convin2(x2)\n",
    "#         print(x1.shape)\n",
    "#         print(x2.shape)\n",
    "#         x = torch.cat([x1_ ,x2_], 1)\n",
    "#         print(x.shape)\n",
    "#         x_ = self.conv3(x)\n",
    "#         out = self.subpixelconv(x_)\n",
    "        \n",
    "#         return out\n",
    "\n",
    "# class double_conv(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "#         super(double_conv, self).__init__()\n",
    "#         self.conv = nn.Sequential(\n",
    "#                     nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,stride=stride, padding=padding),\n",
    "#                     nn.BatchNorm2d(out_channels),\n",
    "#                     nn.ReLU(inplace=True),\n",
    "#                     nn.Dropout2d(p=0.2),\n",
    "#                     nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size,stride=stride, padding=padding),\n",
    "#                     nn.BatchNorm2d(out_channels),\n",
    "#                     nn.ReLU(inplace=True),\n",
    "#                     nn.Dropout2d(p=0.2))\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         return x\n",
    "\n",
    "# class CED(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(CED, self).__init__()\n",
    "        \n",
    "#         # Input 72*72*fm\n",
    "        \n",
    "#         #Contracting Path       \n",
    "#         self.double_conv1 = double_conv(3, 32, 3, 1, 1) #72*72*32\n",
    "#         self.maxpool1 = nn.MaxPool2d(kernel_size=2) #36*36*32\n",
    "        \n",
    "#         self.double_conv2 = double_conv(32, 64, 3, 1, 1) #36*36*64\n",
    "#         self.maxpool2 = nn.MaxPool2d(kernel_size=2) #18*18*64\n",
    "        \n",
    "#         self.double_conv3 = double_conv(64, 128, 3, 1, 1) #18*18*128\n",
    "#         self.maxpool3 = nn.MaxPool2d(kernel_size=2) #9*9*128\n",
    "        \n",
    "#         self.double_conv4 = double_conv(128, 256, 3, 1, 1) #9*9*256\n",
    "#         self.maxpool4 = nn.MaxPool2d(kernel_size=2) #5*5*256\n",
    "        \n",
    "#         self.double_conv5 = double_conv(256, 512, 3, 1, 1) #5*5*256\n",
    "        \n",
    "#         self.t_conv4 = nn.ConvTranspose2d(512, 256, 2, 2,output_padding=1)\n",
    "#         self.ex_double_conv4 = double_conv(256, 256, 3, 1, 1) \n",
    "        \n",
    "#         self.refine1 = refinement_module(256,256,128,3,1,1)\n",
    "#         self.t_conv3 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
    "#         self.ex_double_conv3 = double_conv(128, 128, 3, 1, 1)\n",
    "        \n",
    "#         self.refine2 = refinement_module(128,128,64,3,1,1)\n",
    "#         self.t_conv2 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
    "#         self.ex_double_conv2 = double_conv(64, 64, 3, 1, 1)\n",
    "\n",
    "#         self.refine3 = refinement_module(64,64,32,3,1,1)\n",
    "\n",
    "#         self.convin = nn.Sequential(\n",
    "#             nn.Conv2d(32,16,3,1,1),\n",
    "#             nn.ReLU(inplace=True))\n",
    "#         self.convout = nn.Sequential(\n",
    "#             nn.Conv2d(32,1,3,1,1),\n",
    "#             nn.ReLU(inplace=True))\n",
    "        \n",
    "        \n",
    "#     def forward(self, inputs):\n",
    "#         # Contracting Path\n",
    "#         conv1 = self.double_conv1(inputs)\n",
    "#         print(conv1.shape)\n",
    "#         maxpool1 = self.maxpool1(conv1)\n",
    "#         print(maxpool1.shape)\n",
    "\n",
    "#         conv2 = self.double_conv2(maxpool1)\n",
    "#         maxpool2 = self.maxpool2(conv2)\n",
    "\n",
    "#         conv3 = self.double_conv3(maxpool2)\n",
    "#         maxpool3 = self.maxpool3(conv3)\n",
    "        \n",
    "#         conv4 = self.double_conv4(maxpool3)\n",
    "#         maxpool4 = self.maxpool4(conv4)\n",
    "        \n",
    "#         # Bottom\n",
    "#         conv5 = self.double_conv5(maxpool4)\n",
    "#         print(conv2.shape,maxpool2.shape,conv3.shape, maxpool3.shape,conv4.shape,maxpool4.shape,conv5.shape)\n",
    "#         # Expanding Path\n",
    "        \n",
    "#         t_conv4 = self.t_conv4(conv5)\n",
    "#         print(t_conv4.shape)\n",
    "#         ex_conv4 = self.ex_double_conv4(t_conv4)\n",
    "#         print(ex_conv4.shape)\n",
    "\n",
    "#         refine1out = self.refine1(ex_conv4,conv4)\n",
    "#         print(\"refine1out.shape\",refine1out.shape)\n",
    "# #         t_conv3 = self.t_conv3(refine1out)\n",
    "# #         print(t_conv3.shape)\n",
    "# #         ex_conv3 = self.ex_double_conv3(t_conv3)\n",
    "# #         print(ex_conv3.shape)\n",
    "# #         ex_conv3 = self.ex_double_conv3(refine1out)\n",
    "#         refine2out = self.refine2(refine1out,conv3)\n",
    "# #         t_conv2 = self.t_conv2(refine2out)\n",
    "# #         print(t_conv2.shape)\n",
    "# #         ex_conv2 = self.ex_double_conv2(t_conv2)\n",
    "# #         print(ex_conv2.shape)\n",
    "# #         ex_conv2 = self.ex_double_conv2(refine2out)\n",
    "#         refine3out = self.refine3(refine2out,conv2)\n",
    "        \n",
    "#         in1 = self.convin(refine3out)\n",
    "#         in2 = self.convin(conv1)\n",
    "#         x = torch.cat([in1,in2], 1)\n",
    "#         out = self.convout(x)\n",
    "        \n",
    "#         return torch.sigmoid(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class refinement_module(nn.Module):\n",
    "    def __init__(self, in_chan1, in_chan2, out_chan, kernel_size=3,stride=1,padding=1):\n",
    "        super(refinement_module,self).__init__()\n",
    "        self.convin1 = nn.Sequential(\n",
    "            nn.Conv2d(in_chan1,int(in_chan1/2), kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.convin2 = nn.Sequential(\n",
    "            nn.Conv2d(in_chan2,int(in_chan2/2), kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(int(in_chan1/2)+int(in_chan2/2), out_chan, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.subpixelconv = nn.Sequential(\n",
    "            nn.Conv2d(out_chan, 4*out_chan, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.PixelShuffle(2)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x1,x2):\n",
    "        x1_ = self.convin1(x1)\n",
    "        x2_ = self.convin2(x2)\n",
    "#         print(x1.shape)\n",
    "#         print(x2.shape)\n",
    "        x1_ = crop(x1_, x2_.shape[2], x2_.shape[3])\n",
    "        x = torch.cat([x1_ ,x2_], 1)\n",
    "#         print(x.shape)\n",
    "        x_ = self.conv3(x)\n",
    "        out = self.subpixelconv(x_)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class CED(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CED, self).__init__()\n",
    "        #lr 1 2 decay 1 0\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.conv1_1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(256, 256, kernel_size=3,stride=1, padding=2, dilation=2)\n",
    "        self.conv5_2 = nn.Conv2d(256, 256, kernel_size=3,stride=1, padding=2, dilation=2)\n",
    "        self.conv5_3 = nn.Conv2d(256, 256, kernel_size=3,stride=1, padding=2, dilation=2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "        self.maxpool4 = nn.MaxPool2d(2, stride=1, ceil_mode=True)\n",
    "        \n",
    "        self.t_conv4 = nn.ConvTranspose2d(256, 256, 2, 2)\n",
    "        \n",
    "        self.refine1 = refinement_module(256,256,128,3,1,1)\n",
    "        self.refine2 = refinement_module(128,128,64,3,1,1)\n",
    "        self.refine3 = refinement_module(64,64,32,3,1,1)\n",
    "\n",
    "        self.convin = nn.Sequential(\n",
    "            nn.Conv2d(32,16,3,1,1),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.convout = nn.Sequential(\n",
    "            nn.Conv2d(32,1,3,1,1),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # VGG\n",
    "        img_H, img_W = x.shape[2], x.shape[3]\n",
    "        conv1_1 = self.dropout(self.relu(self.conv1_1(x)))\n",
    "        conv1_2 = self.dropout(self.relu(self.conv1_2(conv1_1)))\n",
    "        pool1   = self.maxpool(conv1_2)\n",
    "\n",
    "        conv2_1 = self.dropout(self.relu(self.conv2_1(pool1)))\n",
    "        conv2_2 = self.dropout(self.relu(self.conv2_2(conv2_1)))\n",
    "        pool2   = self.maxpool(conv2_2)\n",
    "\n",
    "        conv3_1 = self.dropout(self.relu(self.conv3_1(pool2)))\n",
    "        conv3_2 = self.dropout(self.relu(self.conv3_2(conv3_1)))\n",
    "        conv3_3 = self.dropout(self.relu(self.conv3_3(conv3_2)))\n",
    "        pool3   = self.maxpool(conv3_3)\n",
    "\n",
    "        conv4_1 = self.dropout(self.relu(self.conv4_1(pool3)))\n",
    "        conv4_2 = self.dropout(self.relu(self.conv4_2(conv4_1)))\n",
    "        conv4_3 = self.dropout(self.relu(self.conv4_3(conv4_2)))\n",
    "        pool4   = self.maxpool4(conv4_3)\n",
    "\n",
    "        # Bottom\n",
    "        conv5_1 = self.dropout(self.relu(self.conv5_1(pool4)))\n",
    "        conv5_2 = self.dropout(self.relu(self.conv5_2(conv5_1)))\n",
    "        conv5_3 = self.dropout(self.relu(self.conv5_3(conv5_2)))\n",
    "        \n",
    "#         print(conv1_2.shape, pool1.shape, \n",
    "#               conv2_2.shape, pool2.shape, \n",
    "#               conv3_3.shape, pool3.shape, \n",
    "#               conv4_3.shape, pool4.shape, \n",
    "#               conv5_3.shape)\n",
    "        \n",
    "        # Expanding Path\n",
    "        t_conv4 = self.t_conv4(conv5_3)\n",
    "#         print(t_conv4.shape)\n",
    "#         print(\"------------\")\n",
    "\n",
    "        refine1out = self.refine1(t_conv4,conv4_3)\n",
    "#         print(\"refine1out.shape\",refine1out.shape)\n",
    "\n",
    "        refine2out = self.refine2(refine1out,conv3_3)\n",
    "#         print(\"refine2out.shape\",refine2out.shape)\n",
    "\n",
    "        refine3out = self.refine3(refine2out,conv2_2)\n",
    "#         print(\"refine3out.shape\",refine3out.shape)\n",
    "        \n",
    "        in1 = self.convin(refine3out)\n",
    "        in2 = self.convin(conv1_2)\n",
    "        in1 = crop(in1, in2.shape[2], in2.shape[3])\n",
    "        x = torch.cat([in1,in2], 1)\n",
    "        out = self.convout(x)\n",
    "        \n",
    "        assert out.shape[2] == img_H\n",
    "        assert out.shape[3] == img_W\n",
    "        \n",
    "        return torch.sigmoid(out) \n",
    " \n",
    "        \n",
    "        ### center crop\n",
    "#         so1 = crop(so1_out, img_H, img_W)\n",
    "\n",
    "    \n",
    "def crop(variable, th, tw):\n",
    "        h, w = variable.shape[2], variable.shape[3]\n",
    "        x1 = int(round((w - tw) / 2.))\n",
    "        y1 = int(round((h - th) / 2.))\n",
    "        return variable[:, :, y1 : y1 + th, x1 : x1 + tw]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 121, 121]             896\n",
      "              ReLU-2         [-1, 32, 121, 121]               0\n",
      "           Dropout-3         [-1, 32, 121, 121]               0\n",
      "            Conv2d-4         [-1, 32, 121, 121]           9,248\n",
      "              ReLU-5         [-1, 32, 121, 121]               0\n",
      "           Dropout-6         [-1, 32, 121, 121]               0\n",
      "         MaxPool2d-7           [-1, 32, 61, 61]               0\n",
      "            Conv2d-8           [-1, 64, 61, 61]          18,496\n",
      "              ReLU-9           [-1, 64, 61, 61]               0\n",
      "          Dropout-10           [-1, 64, 61, 61]               0\n",
      "           Conv2d-11           [-1, 64, 61, 61]          36,928\n",
      "             ReLU-12           [-1, 64, 61, 61]               0\n",
      "          Dropout-13           [-1, 64, 61, 61]               0\n",
      "        MaxPool2d-14           [-1, 64, 31, 31]               0\n",
      "           Conv2d-15          [-1, 128, 31, 31]          73,856\n",
      "             ReLU-16          [-1, 128, 31, 31]               0\n",
      "          Dropout-17          [-1, 128, 31, 31]               0\n",
      "           Conv2d-18          [-1, 128, 31, 31]         147,584\n",
      "             ReLU-19          [-1, 128, 31, 31]               0\n",
      "          Dropout-20          [-1, 128, 31, 31]               0\n",
      "           Conv2d-21          [-1, 128, 31, 31]         147,584\n",
      "             ReLU-22          [-1, 128, 31, 31]               0\n",
      "          Dropout-23          [-1, 128, 31, 31]               0\n",
      "        MaxPool2d-24          [-1, 128, 16, 16]               0\n",
      "           Conv2d-25          [-1, 256, 16, 16]         295,168\n",
      "             ReLU-26          [-1, 256, 16, 16]               0\n",
      "          Dropout-27          [-1, 256, 16, 16]               0\n",
      "           Conv2d-28          [-1, 256, 16, 16]         590,080\n",
      "             ReLU-29          [-1, 256, 16, 16]               0\n",
      "          Dropout-30          [-1, 256, 16, 16]               0\n",
      "           Conv2d-31          [-1, 256, 16, 16]         590,080\n",
      "             ReLU-32          [-1, 256, 16, 16]               0\n",
      "          Dropout-33          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-34          [-1, 256, 15, 15]               0\n",
      "           Conv2d-35          [-1, 256, 15, 15]         590,080\n",
      "             ReLU-36          [-1, 256, 15, 15]               0\n",
      "          Dropout-37          [-1, 256, 15, 15]               0\n",
      "           Conv2d-38          [-1, 256, 15, 15]         590,080\n",
      "             ReLU-39          [-1, 256, 15, 15]               0\n",
      "          Dropout-40          [-1, 256, 15, 15]               0\n",
      "           Conv2d-41          [-1, 256, 15, 15]         590,080\n",
      "             ReLU-42          [-1, 256, 15, 15]               0\n",
      "          Dropout-43          [-1, 256, 15, 15]               0\n",
      "  ConvTranspose2d-44          [-1, 256, 30, 30]         262,400\n",
      "           Conv2d-45          [-1, 128, 30, 30]         295,040\n",
      "             ReLU-46          [-1, 128, 30, 30]               0\n",
      "           Conv2d-47          [-1, 128, 16, 16]         295,040\n",
      "             ReLU-48          [-1, 128, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]         295,040\n",
      "             ReLU-50          [-1, 128, 16, 16]               0\n",
      "           Conv2d-51          [-1, 512, 16, 16]         590,336\n",
      "     PixelShuffle-52          [-1, 128, 32, 32]               0\n",
      "refinement_module-53          [-1, 128, 32, 32]               0\n",
      "           Conv2d-54           [-1, 64, 32, 32]          73,792\n",
      "             ReLU-55           [-1, 64, 32, 32]               0\n",
      "           Conv2d-56           [-1, 64, 31, 31]          73,792\n",
      "             ReLU-57           [-1, 64, 31, 31]               0\n",
      "           Conv2d-58           [-1, 64, 31, 31]          73,792\n",
      "             ReLU-59           [-1, 64, 31, 31]               0\n",
      "           Conv2d-60          [-1, 256, 31, 31]         147,712\n",
      "     PixelShuffle-61           [-1, 64, 62, 62]               0\n",
      "refinement_module-62           [-1, 64, 62, 62]               0\n",
      "           Conv2d-63           [-1, 32, 62, 62]          18,464\n",
      "             ReLU-64           [-1, 32, 62, 62]               0\n",
      "           Conv2d-65           [-1, 32, 61, 61]          18,464\n",
      "             ReLU-66           [-1, 32, 61, 61]               0\n",
      "           Conv2d-67           [-1, 32, 61, 61]          18,464\n",
      "             ReLU-68           [-1, 32, 61, 61]               0\n",
      "           Conv2d-69          [-1, 128, 61, 61]          36,992\n",
      "     PixelShuffle-70         [-1, 32, 122, 122]               0\n",
      "refinement_module-71         [-1, 32, 122, 122]               0\n",
      "           Conv2d-72         [-1, 16, 122, 122]           4,624\n",
      "             ReLU-73         [-1, 16, 122, 122]               0\n",
      "           Conv2d-74         [-1, 16, 121, 121]           4,624\n",
      "             ReLU-75         [-1, 16, 121, 121]               0\n",
      "           Conv2d-76          [-1, 1, 121, 121]             289\n",
      "             ReLU-77          [-1, 1, 121, 121]               0\n",
      "================================================================\n",
      "Total params: 5,889,025\n",
      "Trainable params: 5,889,025\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.17\n",
      "Forward/backward pass size (MB): 91.18\n",
      "Params size (MB): 22.46\n",
      "Estimated Total Size (MB): 113.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CED()\n",
    "model.cuda();\n",
    "summary(model, (3, 121, 121))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
