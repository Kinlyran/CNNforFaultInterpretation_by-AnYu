{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "from functions import *\n",
    "# in order to get reproducable results\n",
    "torch.manual_seed(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "import cmapy\n",
    "from pytorchtools import EarlyStopping\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"  # Only GPU 3 is visible to this code\n",
    "time1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentfolder_path = os.path.abspath(os.path.join(sys.path[0], os.pardir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune with xl2800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectionNo = 2800\n",
    "seis_path = \"./gsbData/gsb_crl_{}.npy\".format(sectionNo)\n",
    "# fault_path = \"./gsbData/gsb_crl_{}_mask.npy\".format(sectionNo)\n",
    "fault_path = \"xl2800realgt.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seis = np.load(seis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 76 484\n"
     ]
    }
   ],
   "source": [
    "IL, Z, XL = seis.shape\n",
    "print(IL, Z, XL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 76, 484)\n"
     ]
    }
   ],
   "source": [
    "fault = np.load(fault_path)\n",
    "print(fault.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f361e41df98>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(fault))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make input is IL, Z, XL order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "best_iou_threshold=0.5\n",
    "epoches = 200\n",
    "patience = 20\n",
    "im_height = Z\n",
    "im_width = XL\n",
    "splitsize = 96\n",
    "stepsize = 1\n",
    "overlapsize = splitsize-stepsize\n",
    "pixelThre = 10 #int(0.03*splitsize*splitsize)\n",
    "print(pixelThre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontal_splits_number 389\n",
      "width_after_pad 484\n",
      "left_pad,right_pad 0 0\n",
      "vertical_splits_number 1\n",
      "height_after_pad 96\n",
      "top_pad,bottom_pad 10 10\n"
     ]
    }
   ],
   "source": [
    "horizontal_splits_number = int(np.ceil((im_width-overlapsize)/stepsize))\n",
    "width_after_pad = stepsize*horizontal_splits_number+overlapsize\n",
    "if width_after_pad < splitsize:\n",
    "    horizontal_splits_number = 1\n",
    "    width_after_pad = splitsize\n",
    "\n",
    "left_pad = int((width_after_pad-im_width)/2)\n",
    "right_pad = width_after_pad-im_width-left_pad\n",
    "print(\"horizontal_splits_number\", horizontal_splits_number)\n",
    "print(\"width_after_pad\", width_after_pad)\n",
    "print(\"left_pad,right_pad\",left_pad,right_pad)\n",
    "\n",
    "\n",
    "vertical_splits_number = int(np.ceil((im_height-overlapsize)/stepsize))\n",
    "height_after_pad = stepsize*vertical_splits_number+overlapsize\n",
    "if height_after_pad <= splitsize:\n",
    "    vertical_splits_number = 1\n",
    "    height_after_pad = splitsize\n",
    "top_pad = int((height_after_pad-im_height)/2)\n",
    "bottom_pad = height_after_pad-im_height-top_pad\n",
    "print(\"vertical_splits_number\",vertical_splits_number)\n",
    "print(\"height_after_pad\",height_after_pad)\n",
    "print(\"top_pad,bottom_pad\", top_pad,bottom_pad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\n",
      "389\n",
      "(96, 96)\n",
      "read images in 0.031225204467773438 sec\n",
      "(389, 96, 96)\n",
      "(389, 96, 96)\n",
      "read images in 0.024305343627929688 sec\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(len(seis)):\n",
    "    mask = fault[i]\n",
    "    splits = split_Image(mask,True,top_pad,bottom_pad,left_pad,right_pad,splitsize,stepsize,vertical_splits_number,horizontal_splits_number)\n",
    "#     print(splits.shape)\n",
    "    t = (splits.sum((1,2)) < pixelThre)\n",
    "    no_label_element_index = list(compress(range(len(t)), t))\n",
    "    # get all the indexes of the no label pieces by adding elements in axis 2 and 3.\n",
    "    splits = np.delete(splits, no_label_element_index,0) # delete element i along axis 0\n",
    "#     print(\"splits.shape\", splits.shape)\n",
    "    Y.extend(splits)\n",
    "    \n",
    "    img = seis[i]\n",
    "    splits = split_Image(img,True,top_pad,bottom_pad,left_pad,right_pad,splitsize,stepsize,vertical_splits_number,horizontal_splits_number)\n",
    "    splits = np.delete(splits, no_label_element_index,0) # delete element i along axis 0\n",
    "    X.extend(splits)\n",
    "\n",
    "print(len(Y))\n",
    "print(len(X))\n",
    "print(X[0].shape)\n",
    "print(\"read images in {} sec\".format(time.time()-t_start))\n",
    "\n",
    "t_start = time.time()\n",
    "X = np.asarray(X, dtype=np.float32)\n",
    "Y = np.asarray(Y, dtype=np.float32)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(\"read images in {} sec\".format(time.time()-t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389, 96, 96, 1)\n",
      "(389, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "if len(Y.shape) == 3:\n",
    "    Y = np.expand_dims(Y, axis=-1)\n",
    "if len(X.shape) == 3:\n",
    "    X = np.expand_dims(X, axis=-1)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 96, 96, 1) (39, 96, 96, 1)\n",
      "(350, 96, 96, 1) (39, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=1) #,shuffle=False\n",
    "print(X_train.shape, X_val.shape)\n",
    "print(Y_train.shape, Y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "read images in 11.505072593688965 sec\n",
      "X_train after aug (3500, 96, 96, 1)\n",
      "Y_train after aug (3500, 96, 96, 1)\n",
      "read images in 11.942770957946777 sec\n",
      "X_train (3500, 1, 96, 96)\n",
      "X_val (39, 1, 96, 96)\n",
      "Y_train (3500, 1, 96, 96)\n",
      "Y_val (39, 1, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "aug_times = 9\n",
    "\n",
    "t_start = time.time()\n",
    "origin_train_size = len(X_train)\n",
    "print(origin_train_size)\n",
    "X_train_aug = np.zeros((origin_train_size*aug_times,splitsize,splitsize,1))\n",
    "Y_train_aug = np.zeros((origin_train_size*aug_times,splitsize,splitsize,1))\n",
    "for i in range(len(X_train)):\n",
    "    for j in range(aug_times):\n",
    "        aug = strong_aug(p=1)\n",
    "        augmented = aug(image=X_train[i], mask=Y_train[i])\n",
    "        X_train_aug[origin_train_size*j + i] = augmented['image']\n",
    "        Y_train_aug[origin_train_size*j + i] = augmented['mask']\n",
    "print(\"read images in {} sec\".format(time.time()-t_start))\n",
    "\n",
    "X_train_aug = X_train_aug.astype(np.float32)\n",
    "Y_train_aug = Y_train_aug.astype(np.float32)\n",
    "if len(X_train)==origin_train_size:\n",
    "    X_train = np.append(X_train,X_train_aug, axis=0)\n",
    "if len(Y_train)==origin_train_size:\n",
    "    Y_train = np.append(Y_train, Y_train_aug, axis=0)\n",
    "print(\"X_train after aug\",X_train.shape) \n",
    "print(\"Y_train after aug\",Y_train.shape)\n",
    "print(\"read images in {} sec\".format(time.time()-t_start))\n",
    "X_train = X_train.astype(np.float32)\n",
    "Y_train = Y_train.astype(np.float32)\n",
    "#-----------------------\n",
    "X_train = np.moveaxis(X_train,-1,1)\n",
    "Y_train = np.moveaxis(Y_train,-1,1)\n",
    "X_val = np.moveaxis(X_val,-1,1)\n",
    "Y_val = np.moveaxis(Y_val,-1,1)\n",
    "print(\"X_train\",X_train.shape)\n",
    "print(\"X_val\",X_val.shape)\n",
    "print(\"Y_train\",Y_train.shape)\n",
    "print(\"Y_val\",Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use model RCF\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 96, 96]             320\n",
      "              ReLU-2           [-1, 32, 96, 96]               0\n",
      "         Dropout2d-3           [-1, 32, 96, 96]               0\n",
      "            Conv2d-4           [-1, 32, 96, 96]           9,248\n",
      "              ReLU-5           [-1, 32, 96, 96]               0\n",
      "         Dropout2d-6           [-1, 32, 96, 96]               0\n",
      "         MaxPool2d-7           [-1, 32, 48, 48]               0\n",
      "            Conv2d-8           [-1, 64, 48, 48]          18,496\n",
      "              ReLU-9           [-1, 64, 48, 48]               0\n",
      "        Dropout2d-10           [-1, 64, 48, 48]               0\n",
      "           Conv2d-11           [-1, 64, 48, 48]          36,928\n",
      "             ReLU-12           [-1, 64, 48, 48]               0\n",
      "        Dropout2d-13           [-1, 64, 48, 48]               0\n",
      "        MaxPool2d-14           [-1, 64, 24, 24]               0\n",
      "           Conv2d-15          [-1, 128, 24, 24]          73,856\n",
      "             ReLU-16          [-1, 128, 24, 24]               0\n",
      "        Dropout2d-17          [-1, 128, 24, 24]               0\n",
      "           Conv2d-18          [-1, 128, 24, 24]         147,584\n",
      "             ReLU-19          [-1, 128, 24, 24]               0\n",
      "        Dropout2d-20          [-1, 128, 24, 24]               0\n",
      "           Conv2d-21          [-1, 128, 24, 24]         147,584\n",
      "             ReLU-22          [-1, 128, 24, 24]               0\n",
      "        Dropout2d-23          [-1, 128, 24, 24]               0\n",
      "        MaxPool2d-24          [-1, 128, 12, 12]               0\n",
      "           Conv2d-25          [-1, 256, 12, 12]         295,168\n",
      "             ReLU-26          [-1, 256, 12, 12]               0\n",
      "        Dropout2d-27          [-1, 256, 12, 12]               0\n",
      "           Conv2d-28          [-1, 256, 12, 12]         590,080\n",
      "             ReLU-29          [-1, 256, 12, 12]               0\n",
      "        Dropout2d-30          [-1, 256, 12, 12]               0\n",
      "           Conv2d-31          [-1, 256, 12, 12]         590,080\n",
      "             ReLU-32          [-1, 256, 12, 12]               0\n",
      "        Dropout2d-33          [-1, 256, 12, 12]               0\n",
      "        MaxPool2d-34          [-1, 256, 11, 11]               0\n",
      "           Conv2d-35          [-1, 256, 11, 11]         590,080\n",
      "             ReLU-36          [-1, 256, 11, 11]               0\n",
      "        Dropout2d-37          [-1, 256, 11, 11]               0\n",
      "           Conv2d-38          [-1, 256, 11, 11]         590,080\n",
      "             ReLU-39          [-1, 256, 11, 11]               0\n",
      "        Dropout2d-40          [-1, 256, 11, 11]               0\n",
      "           Conv2d-41          [-1, 256, 11, 11]         590,080\n",
      "             ReLU-42          [-1, 256, 11, 11]               0\n",
      "        Dropout2d-43          [-1, 256, 11, 11]               0\n",
      "           Conv2d-44           [-1, 21, 96, 96]             693\n",
      "           Conv2d-45           [-1, 21, 96, 96]             693\n",
      "           Conv2d-46           [-1, 21, 48, 48]           1,365\n",
      "           Conv2d-47           [-1, 21, 48, 48]           1,365\n",
      "           Conv2d-48           [-1, 21, 24, 24]           2,709\n",
      "           Conv2d-49           [-1, 21, 24, 24]           2,709\n",
      "           Conv2d-50           [-1, 21, 24, 24]           2,709\n",
      "           Conv2d-51           [-1, 21, 12, 12]           5,397\n",
      "           Conv2d-52           [-1, 21, 12, 12]           5,397\n",
      "           Conv2d-53           [-1, 21, 12, 12]           5,397\n",
      "           Conv2d-54           [-1, 21, 11, 11]           5,397\n",
      "           Conv2d-55           [-1, 21, 11, 11]           5,397\n",
      "           Conv2d-56           [-1, 21, 11, 11]           5,397\n",
      "           Conv2d-57            [-1, 1, 96, 96]              22\n",
      "           Conv2d-58            [-1, 1, 48, 48]              22\n",
      "           Conv2d-59            [-1, 1, 24, 24]              22\n",
      "           Conv2d-60            [-1, 1, 12, 12]              22\n",
      "           Conv2d-61            [-1, 1, 11, 11]              22\n",
      "           Conv2d-62            [-1, 1, 96, 96]               6\n",
      "================================================================\n",
      "Total params: 3,724,325\n",
      "Trainable params: 3,724,325\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 35.45\n",
      "Params size (MB): 14.21\n",
      "Estimated Total Size (MB): 49.69\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "modelNo = \"rcf\" # select one of [\"unet\", \"deeplab\", \"hed\", \"rcf\"]\n",
    "checkpoint_path = \"{}/checkpoints/noaugmodelsseed\".format(parentfolder_path)\n",
    "device = torch.device(\"cuda\")\n",
    "finetune_path = \"{}/checkpoints/finetune\".format(parentfolder_path)\n",
    "if not os.path.exists(finetune_path):\n",
    "    os.makedirs(finetune_path)\n",
    "if modelNo == \"unet\":\n",
    "    from model_zoo.UNET import Unet\n",
    "    model = Unet()\n",
    "    print(\"use model Unet\")\n",
    "    modelname = \"unet_ft_96_1_shuffle_thick_9aug\"\n",
    "    best_model_fpath = '{}/{}.model'.format(checkpoint_path,\"unet_96_48_900200_seed\") \n",
    "    save_path = '{}/{}.model'.format(finetune_path,modelname)\n",
    "elif modelNo == \"deeplab\":\n",
    "    from model_zoo.DEEPLAB.deeplab import DeepLab\n",
    "    model = DeepLab(backbone='mobilenet', num_classes=1, output_stride=16)\n",
    "    print(\"use model DeepLab\")\n",
    "    modelname = \"deeplab_ft_96_1_shuffle_thick_9aug\"\n",
    "    best_model_fpath = '{}/{}.model'.format(checkpoint_path,\"mobilenet_96_48_900200_seed\") \n",
    "    save_path = '{}/{}.model'.format(finetune_path,modelname)\n",
    "elif modelNo == \"hed\":\n",
    "    from model_zoo.HED import HED\n",
    "    model = HED()\n",
    "    print(\"use model HED\") \n",
    "    modelname = \"hed_ft_96_1_shuffle_thick_9aug\"\n",
    "    best_model_fpath = '{}/{}.model'.format(checkpoint_path,\"hed_96_48_900200_seed3\") \n",
    "    save_path = '{}/{}.model'.format(finetune_path,modelname)\n",
    "elif modelNo == \"rcf\":\n",
    "    from model_zoo.RCF import RCF\n",
    "    model = RCF()\n",
    "    print(\"use model RCF\")\n",
    "    modelname = \"rcf_ft_96_1_shuffle_thick_9aug\"\n",
    "    best_model_fpath = '{}/{}.model'.format(checkpoint_path,\"rcf_96_48_900200_seed\") \n",
    "    save_path = '{}/{}.model'.format(finetune_path,modelname)\n",
    "else:\n",
    "    print(\"please enter a valid model\")\n",
    "# print(best_model_fpath)\n",
    "# print(save_path)\n",
    "model.load_state_dict(torch.load(best_model_fpath, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n",
    "model.to(device)\n",
    "summary(model, (1, splitsize, splitsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "# idea from: https://www.kaggle.com/erikistre/pytorch-basic-u-net\n",
    "class faultsDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,preprocessed_images,train=True, preprocessed_masks=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text_file(string): path to text file\n",
    "            root_dir(string): directory with all train images\n",
    "        \"\"\"\n",
    "        self.train = train\n",
    "        self.images = preprocessed_images\n",
    "        self.masks = preprocessed_masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        return (image, mask)\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "faults_dataset_train = faultsDataset(X_train, train=True, preprocessed_masks=Y_train)\n",
    "faults_dataset_val = faultsDataset(X_val, train=False, preprocessed_masks=Y_val)\n",
    "\n",
    "\n",
    "batch_size = 64 \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=faults_dataset_train, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=faults_dataset_val, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6, momentum=0.9, weight_decay=0.0002)\n",
      "Validation loss decreased (inf --> 2743584.750000).  Saving model ...\n",
      "Epoch: 1. Train Loss: 5170969.5. Val Loss: 2743584.75. Train IoU: 0.119720958173275. Val IoU: 0.13633288443088531. Time: 17.84481167793274. LR: 1e-09\n",
      "Validation loss decreased (2743584.750000 --> 2263545.250000).  Saving model ...\n",
      "Epoch: 2. Train Loss: 4695656.5. Val Loss: 2263545.25. Train IoU: 0.14254087209701538. Val IoU: 0.20634368062019348. Time: 16.68990397453308. LR: 1e-09\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e4057c67c61a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodelNo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"rcf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_entropy_loss_RCF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myproject/venv/an/all_model_new/paper1/paper1-researchpaper/functions.py\u001b[0m in \u001b[0;36mcross_entropy_loss_RCF\u001b[0;34m(prediction, label)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mnum_negative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_negative\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_positive\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_negative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_positive\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_positive\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_negative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     cost = torch.nn.functional.binary_cross_entropy(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-9, momentum=0.9, weight_decay=0.0002)\n",
    "print(\"optimizer = torch.optim.SGD(model.parameters(), lr=1e-6, momentum=0.9, weight_decay=0.0002)\")\n",
    "if modelNo == \"unet\" or modelNo == \"deeplab\":\n",
    "    print(\"optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.1, patience=10, eps=1e-15,verbose=True)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "bceloss = nn.BCELoss()\n",
    "mean_train_losses = []\n",
    "mean_val_losses = []\n",
    "mean_train_accuracies = []\n",
    "mean_val_accuracies = []\n",
    "t_start = time.time()\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True, delta = 0)\n",
    "for epoch in range(epoches):                  \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    labelled_val_accuracies = []\n",
    "\n",
    "    model.train()\n",
    "    for images, masks in train_loader: \n",
    "        torch.cuda.empty_cache()\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = torch.zeros(1).cuda()\n",
    "        y_preds = outputs\n",
    "        if modelNo == \"unet\" or modelNo == \"deeplab\":\n",
    "            loss = bceloss(outputs, masks) \n",
    "        elif modelNo == \"hed\":\n",
    "            for o in range(5):\n",
    "                loss = loss + cross_entropy_loss_HED(outputs[o], masks)\n",
    "            loss = loss + bceloss(outputs[-1],masks)\n",
    "            y_preds = outputs[-2]\n",
    "        elif modelNo == \"rcf\":\n",
    "            for o in outputs:\n",
    "                loss = loss + cross_entropy_loss_RCF(o, masks)\n",
    "            y_preds = outputs[-1]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_losses.append(loss.data)\n",
    "        predicted_mask = y_preds > best_iou_threshold\n",
    "        train_acc = iou_pytorch(predicted_mask.squeeze(1).byte(), masks.squeeze(1).byte())\n",
    "        train_accuracies.append(train_acc.mean())        \n",
    "\n",
    "    model.eval()\n",
    "    for images, masks in val_loader:\n",
    "        torch.cuda.empty_cache()\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = torch.zeros(1).cuda()\n",
    "        y_preds = outputs\n",
    "        if modelNo == \"unet\" or modelNo == \"deeplab\":\n",
    "            loss = bceloss(outputs, masks) \n",
    "        elif modelNo == \"hed\":\n",
    "            for o in range(5):\n",
    "                loss = loss + cross_entropy_loss_HED(outputs[o], masks)\n",
    "            loss = loss + bceloss(outputs[-1],masks)\n",
    "            y_preds = outputs[-2]\n",
    "        elif modelNo == \"rcf\":\n",
    "            for o in outputs:\n",
    "                loss = loss + cross_entropy_loss_RCF(o, masks)\n",
    "            y_preds = outputs[-1]\n",
    "        val_losses.append(loss.data)\n",
    "        predicted_mask = y_preds > best_iou_threshold\n",
    "        val_acc = iou_pytorch(predicted_mask.byte(), masks.squeeze(1).byte())\n",
    "        val_accuracies.append(val_acc.mean())\n",
    "\n",
    "        \n",
    "    mean_train_losses.append(torch.mean(torch.stack(train_losses)))\n",
    "    mean_val_losses.append(torch.mean(torch.stack(val_losses)))\n",
    "    mean_train_accuracies.append(torch.mean(torch.stack(train_accuracies)))\n",
    "    mean_val_accuracies.append(torch.mean(torch.stack(val_accuracies)))\n",
    "    \n",
    "    scheduler.step(torch.mean(torch.stack(val_losses)))    \n",
    "    early_stopping(torch.mean(torch.stack(val_losses)), model, save_path)\n",
    "\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "        \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        learningRate = param_group['lr']\n",
    "    \n",
    "    \n",
    "    # Print Epoch results\n",
    "    t_end = time.time()\n",
    "\n",
    "    print('Epoch: {}. Train Loss: {}. Val Loss: {}. Train IoU: {}. Val IoU: {}. Time: {}. LR: {}'\n",
    "          .format(epoch+1, torch.mean(torch.stack(train_losses)), torch.mean(torch.stack(val_losses)), torch.mean(torch.stack(train_accuracies)), torch.mean(torch.stack(val_accuracies)), t_end-t_start, learningRate))\n",
    "    \n",
    "    t_start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "mean_train_losses = np.asarray(torch.stack(mean_train_losses).cpu())\n",
    "mean_val_losses = np.asarray(torch.stack(mean_val_losses).cpu())\n",
    "mean_train_accuracies = np.asarray(torch.stack(mean_train_accuracies).cpu())\n",
    "mean_val_accuracies = np.asarray(torch.stack(mean_val_accuracies).cpu())\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "train_loss_series = pd.Series(mean_train_losses)\n",
    "val_loss_series = pd.Series(mean_val_losses)\n",
    "train_loss_series.plot(label=\"train_loss\")\n",
    "val_loss_series.plot(label=\"validation_loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "train_acc_series = pd.Series(mean_train_accuracies)\n",
    "val_acc_series = pd.Series(mean_val_accuracies)\n",
    "train_acc_series.plot(label=\"train_acc\")\n",
    "val_acc_series.plot(label=\"validation_acc\")\n",
    "plt.legend()\n",
    "plt.savefig('{}_loss_acc.png'.format(best_model_fpath))\n",
    "\n",
    "totaltime = time.time()-time1\n",
    "print(\"total cost {} seconds\".format(totaltime))\n",
    "print(\"total cost {} hours\".format(totaltime/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
